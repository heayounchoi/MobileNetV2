{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "nQdPo_1HBJ3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6409e0e8-eebd-4920-bf94-ae2e57a39c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epr-gytcc7B8",
        "outputId": "ec54d283-2951-45a1-cf8c-8614a6024a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "checkpoints = '/content/drive/MyDrive/Colab Notebooks/MobileNetV2/checkpoints/'\n",
        "if not os.path.exists(checkpoints):\n",
        "    os.makedirs(checkpoints)"
      ],
      "metadata": {
        "id": "grWWJ68tdrnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/drive/MyDrive/Colab Notebooks/MobileNetV2/checkpoints/MobileNetV2_9/\""
      ],
      "metadata": {
        "id": "dJ1RredGYpyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchinfo"
      ],
      "metadata": {
        "id": "XBZquGBlQIac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "5KfP_j8el47n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wandb"
      ],
      "metadata": {
        "id": "H6pBBgG9ut5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "Qe3QexcVu--r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login --relogin"
      ],
      "metadata": {
        "id": "EQ-ytDqxVmzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "wandb.init(\n",
        "    project=\"MobileNetV2\",\n",
        "    group=\"MobileNetV2\",\n",
        "    name=\"9\",\n",
        "    notes=\"MobileNetV2_9\",\n",
        ")"
      ],
      "metadata": {
        "id": "4NhnNMhB3eGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, 4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root=\"/content/drive/MyDrive/Colab Notebooks/VGGNet/dataset/\",\n",
        "                                 train=True,\n",
        "                                 download=True,\n",
        "                                 transform=transform)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root=\"/content/drive/MyDrive/Colab Notebooks/VGGNet/dataset/\",\n",
        "                                train=False,\n",
        "                                download=True,\n",
        "                                transform=transform_test)\n",
        "\n",
        "num_classes = len(train_dataset.classes)\n",
        "\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "validation_size = len(train_dataset) - train_size\n",
        "\n",
        "train_dataset, validation_dataset = random_split(train_dataset, [train_size, validation_size])"
      ],
      "metadata": {
        "id": "ahtvUXsNmWRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "\n",
        "validation_loader = DataLoader(dataset=validation_dataset,\n",
        "                               batch_size=BATCH_SIZE,\n",
        "                               shuffle=False)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=64,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "91mwq3mEExu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_size = 0\n",
        "for (X_train, Y_train) in train_loader:\n",
        "    X_train_size = X_train.size()[1:]\n",
        "    print(X_train_size)\n",
        "    print(f\"X_train: {X_train.size()} type: {X_train.type()}\")\n",
        "    print(f\"Y_train: {Y_train.size()} type: {Y_train.type()}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "7ukHoTyJWRfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"사용하는 Device :\", DEVICE)"
      ],
      "metadata": {
        "id": "qfMM7Gopny0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, expansion, stride):\n",
        "        super(Block, self).__init__()\n",
        "        self.stride = stride\n",
        "\n",
        "        planes = expansion * in_planes\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, planes, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(planes),\n",
        "            nn.ReLU6(),\n",
        "            nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, groups=planes, bias=False),\n",
        "            nn.BatchNorm2d(planes),\n",
        "            nn.ReLU6(),\n",
        "            nn.Conv2d(planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(out_planes)\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride == 1 and in_planes != out_planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "                nn.BatchNorm2d(out_planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out + self.shortcut(x) if self.stride == 1 else out\n",
        "        return out\n",
        "\n",
        "\n",
        "class MobileNetV2(nn.Module):\n",
        "    # (expansion, out_planes, num_blocks, stride)\n",
        "    cfg = [(1,  32, 1, 1),\n",
        "           (4,  48, 2, 1),\n",
        "           (4,  64, 3, 2),\n",
        "           (4, 128, 4, 2),\n",
        "           (4, 256, 3, 2)]\n",
        "\n",
        "    def __init__(self, num_classes=num_classes):\n",
        "        super(MobileNetV2, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            self._make_layers(in_planes=64),\n",
        "            nn.Conv2d(256, 512, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.linear = nn.Linear(512, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, std=1e-3)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def _make_layers(self, in_planes):\n",
        "        layers = []\n",
        "        for expansion, out_planes, num_blocks, stride in self.cfg:\n",
        "            strides = [stride] + [1]*(num_blocks-1)\n",
        "            for stride in strides:\n",
        "                layers.append(Block(in_planes, out_planes, expansion, stride))\n",
        "                in_planes = out_planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "t-PosP7q4Doh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MobileNetV2().to(DEVICE)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(model)\n",
        "print(f\"총 파라미터 개수: {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJi10HdxDX7e",
        "outputId": "2a1dfd1f-f877-49aa-859c-48a38cc1f52b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MobileNetV2(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Sequential(\n",
            "      (0): Block(\n",
            "        (features): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6()\n",
            "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU6()\n",
            "          (6): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Block(\n",
            "        (features): Sequential(\n",
            "          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6()\n",
            "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU6()\n",
            "          (6): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(32, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (2): Block(\n",
            "        (features): Sequential(\n",
            "          (0): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6()\n",
            "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU6()\n",
            "          (6): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (3): Block(\n",
            "        (features): Sequential(\n",
            "          (0): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6()\n",
            "          (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
            "          (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU6()\n",
            "          (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (4): Block(\n",
            "        (features): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6()\n",
            "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU6()\n",
            "          (6): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (5): Block(\n",
            "        (features): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6()\n",
            "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU6()\n",
            "          (6): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (6): Block(\n",
            "        (features): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6()\n",
            "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
            "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU6()\n",
            "          (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (7): Block(\n",
            "        (features): Sequential(\n",
            "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6()\n",
            "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU6()\n",
            "          (6): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (8): Block(\n",
            "        (features): Sequential(\n",
            "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6()\n",
            "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU6()\n",
            "          (6): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (9): Block(\n",
            "        (features): Sequential(\n",
            "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6()\n",
            "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU6()\n",
            "          (6): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (10): Block(\n",
            "        (features): Sequential(\n",
            "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6()\n",
            "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
            "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU6()\n",
            "          (6): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (11): Block(\n",
            "        (features): Sequential(\n",
            "          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6()\n",
            "          (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "          (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU6()\n",
            "          (6): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "      (12): Block(\n",
            "        (features): Sequential(\n",
            "          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6()\n",
            "          (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "          (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU6()\n",
            "          (6): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential()\n",
            "      )\n",
            "    )\n",
            "    (4): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "  )\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "총 파라미터 개수: 2026154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MobileNetV2().to(DEVICE)\n",
        "summary(model, (1, *X_train_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlhHobbqQO9c",
        "outputId": "52c9090f-48cc-4a09-c486-66b508cf789d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "MobileNetV2                                   [1, 10]                   --\n",
              "├─Sequential: 1-1                             [1, 512, 4, 4]            --\n",
              "│    └─Conv2d: 2-1                            [1, 64, 32, 32]           1,728\n",
              "│    └─BatchNorm2d: 2-2                       [1, 64, 32, 32]           128\n",
              "│    └─ReLU: 2-3                              [1, 64, 32, 32]           --\n",
              "│    └─Sequential: 2-4                        [1, 256, 4, 4]            --\n",
              "│    │    └─Block: 3-1                        [1, 32, 32, 32]           9,152\n",
              "│    │    └─Block: 3-2                        [1, 48, 32, 32]           13,632\n",
              "│    │    └─Block: 3-3                        [1, 48, 32, 32]           21,024\n",
              "│    │    └─Block: 3-4                        [1, 64, 16, 16]           24,128\n",
              "│    │    └─Block: 3-5                        [1, 64, 16, 16]           36,224\n",
              "│    │    └─Block: 3-6                        [1, 64, 16, 16]           36,224\n",
              "│    │    └─Block: 3-7                        [1, 128, 8, 8]            52,736\n",
              "│    │    └─Block: 3-8                        [1, 128, 8, 8]            137,984\n",
              "│    │    └─Block: 3-9                        [1, 128, 8, 8]            137,984\n",
              "│    │    └─Block: 3-10                       [1, 128, 8, 8]            137,984\n",
              "│    │    └─Block: 3-11                       [1, 256, 4, 4]            203,776\n",
              "│    │    └─Block: 3-12                       [1, 256, 4, 4]            538,112\n",
              "│    │    └─Block: 3-13                       [1, 256, 4, 4]            538,112\n",
              "│    └─Conv2d: 2-5                            [1, 512, 4, 4]            131,072\n",
              "│    └─BatchNorm2d: 2-6                       [1, 512, 4, 4]            1,024\n",
              "│    └─ReLU: 2-7                              [1, 512, 4, 4]            --\n",
              "├─Linear: 1-2                                 [1, 10]                   5,130\n",
              "===============================================================================================\n",
              "Total params: 2,026,154\n",
              "Trainable params: 2,026,154\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 133.67\n",
              "===============================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 32.96\n",
              "Params size (MB): 8.10\n",
              "Estimated Total Size (MB): 41.08\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
        "total_epochs = 100\n",
        "\n",
        "try:\n",
        "    checkpoint = torch.load(checkpoints + 'MobileNetV2_9/last_epoch')\n",
        "    old_model_state_dict = checkpoint['model_state_dict']\n",
        "    new_model_state_dict = model.state_dict()\n",
        "\n",
        "    for name, param in old_model_state_dict.items():\n",
        "        if name in new_model_state_dict:\n",
        "            try:\n",
        "                new_model_state_dict[name].copy_(param)\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to copy param: {name}, due to {e}\")\n",
        "\n",
        "    model.load_state_dict(new_model_state_dict, strict=False)\n",
        "\n",
        "    last_epoch = checkpoint['epoch']\n",
        "    best_val_loss = checkpoint[\"best_val_loss\"]\n",
        "    train_losses = checkpoint[\"train_losses\"]\n",
        "    val_losses = checkpoint[\"val_losses\"]\n",
        "\n",
        "except:\n",
        "    checkpoint = None\n",
        "    last_epoch = -1\n",
        "    best_val_loss = float('inf')\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "finally:\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_epochs)\n",
        "    if checkpoint:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "    for epoch in tqdm(range(last_epoch + 1, total_epochs), desc='Epoch Progress'):\n",
        "        avg_cost = 0\n",
        "\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        with tqdm(total=len(train_loader), desc='Batch Progress') as batch_bar:\n",
        "            for X, Y in train_loader:\n",
        "                X = X.to(DEVICE)\n",
        "                Y = Y.to(DEVICE)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                hypothesis = model(X)\n",
        "                loss = criterion(hypothesis, Y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "\n",
        "                _, predicted_train = torch.max(hypothesis.data, 1)\n",
        "                total_train += Y.size(0)\n",
        "                correct_train += (predicted_train == Y).sum().item()\n",
        "\n",
        "                batch_bar.update()\n",
        "\n",
        "            train_losses.append(train_loss / len(train_loader))\n",
        "            train_accuracy = (100 * correct_train) / total_train\n",
        "\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                for X, Y in validation_loader:\n",
        "                    X = X.to(DEVICE)\n",
        "                    Y = Y.to(DEVICE)\n",
        "\n",
        "                    output = model(X)\n",
        "                    _, predicted = torch.max(output, 1)\n",
        "\n",
        "                    val_loss += criterion(output, Y).item()\n",
        "\n",
        "                    total += Y.size(0)\n",
        "                    correct += (predicted == Y).sum().item()\n",
        "\n",
        "                val_losses.append(val_loss / len(validation_loader))\n",
        "                val_accuracy = correct / total\n",
        "                scheduler.step()\n",
        "\n",
        "            train_desc = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'train_accuracy': train_accuracy,\n",
        "            'val_accuracy': val_accuracy * 100,\n",
        "            'train_losses': train_losses,\n",
        "            'val_losses': val_losses,\n",
        "            'best_val_loss': best_val_loss\n",
        "            }\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                torch.save(train_desc, checkpoints + f'MobileNetV2_9/best_epoch')\n",
        "\n",
        "            torch.save(train_desc, checkpoints+f'MobileNetV2_9/last_epoch')\n",
        "\n",
        "            wandb.log({\"train_accuracy\": train_accuracy, \"val_accuracy\": val_accuracy*100,\n",
        "                        \"train_losses\": train_losses[-1], \"val_losses\": val_losses[-1],\n",
        "                        }, step=epoch)\n",
        "\n",
        "            print('Epoch [{}/{}], Train Loss: {:.4f}, Train Accuracy: {:.4f}%, Val Loss: {:.4f}, Val Accuracy: {:.2f}%'\n",
        "                    .format(epoch, total_epochs, train_losses[-1], train_accuracy, val_losses[-1], val_accuracy*100))\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, Y in test_loader:\n",
        "            X = X.to(DEVICE)\n",
        "            Y = Y.to(DEVICE)\n",
        "\n",
        "            output = model(X)\n",
        "            loss = criterion(output, Y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total += Y.size(0)\n",
        "            correct += (predicted == Y).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    test_accuracy = correct / total\n",
        "\n",
        "    wandb.log({\"test_loss\": test_loss, \"test_accuracy\": test_accuracy*100})\n",
        "\n",
        "    wandb.alert(\"[MobileNetV2_9]Training Task Finished\", f\"test accuracy: {test_accuracy*100}\")\n",
        "\n",
        "    wandb.finish()"
      ],
      "metadata": {
        "id": "1CHfsIH6uLoz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}